%INTRO
When developing a \gls{wrtc} client for mobile devices one has two options: either create a HTML5 app or embed \gls{wrtc} into a native app. \gls{wrtc} itself provides a high-quality media engine for voice and video that adapts to network conditions automatically. Security is high due to encryption of media packets. But using the JavaScript APIs or some third-party SDK is one thing, we still have to create a way of doing signaling ourselves, since this is not standardized yet. Creating a client that works for mobile phones is beneficial for the \gls{byod} policy of permitting employees to bring personally owned mobile devices (tablets, smart phones) in enterprises.

\begin{quote}
``Enterprise migration toward tablets from PCs will effectively cause many - if not most - companies to `dismantle' their current business-as-usual approach to technology'' - Eric Schmidt
\end{quote}


\section{Mobile client for WebRTC}
When developing a client for our mobile devices there are a few options. For the Android OS we have advanced implementations of \gls{wrtc} directly integrated in both Chrome and Firefox mobile browsers. But for iOS we have to use third-party SDKs to embed \gls{wrtc} into a native app. Using a web browser application is great when the user has a planned meeting, this way he can open or join an ongoing session, but will not be available to receive incoming calls, when the app is not actively running. It might be beneficial to create native applications for mobile phones, to allow reception of messages for incoming calls. When the user is not actively using the application, it can run in the background.

In the mobile devices section of the background chapter, it was mentioned that the most important issue was how to handle signaling in a way that avoids drainage of the battery. In addition we want to find out if it's possible to do multi-party conferencing. Other problems specific to mobile devices are bandwidth usage, processing limitations, and sound echo.

\section{Bandwidth}
Mobile bandwidth usage comes at a premium, and \gls{wrtc} dynamically adjusts each stream for maximum bandwidth usage at best quality. There is not much we can do about this on the client side, but we should be able to upload lower bandwidth video by setting constraints in the MediaStream objects. 


\section{Processing}
The encoding and decoding of video is CPU expensive. The H.264 codec is the most CPU friendly one, since it has a greater range of devices supporting hardware acceleration. But in this day and age, this is a minor issue that will soon become irrelevant due to the rapid increase in mobile processing power we're seeing\cite{moores-law}. A bigger issue is multi-party streams since software encoding barely supports single streams\cite{webrtc-mobile-slides}, so for conferencing we have to use server side mixing of the streams, to have support for multi-party sessions.


\section{Signaling}
The mobile radio is one of most battery draining units on our mobile phones, so we need to think about how we do our signaling, since keeping an open connection all the time is very expensive. The main issue here is how to listen for incoming connections, when we are actively using our app it's natural to keep an open socket all the time, but when we are not actively using the phone, it might be better to listen only infrequently for incoming calls or opening up a socket when receiving a push notification notifying the user of an incoming call. Both Google's Cloud Messaging (GCM) service and Apple's Push Notification Service (APNS) allows for persistent connections. This will allow the user of a WebRTC application to be alerted that the application has data waiting for it.


\section{Echo cancellation}
The biggest issue relevant to a user is call quality. When the microphone is placed near the speaker a common problem is echo, this happens when the microphone records output from the speaker. This may not be audible for the user, but can be very annoying for the other party. The solution here is to use echo cancellation techniques. This is integrated in the \gls{wrtc} audio engine, but currently it works poorly on mobile devices. The technique used is \gls{aec}. It works by analyzing the sound output being played from your speakers and removes it from the sound captured by your microphone. But lots of Android devices are unable to handle \gls{aec}\cite{echo-problems-mobile}. The lazy solution is to recommend the user to use earplugs/headphones so that the microphone cannot pick up sound from the speakers. The advanced solution would be to implement third-party echo cancellation software specialized to each platform and device.


\section{Summary}
When developing \gls{wrtc} clients for mobile devices, we have to think about problems specific to mobile devices in contrast to desktop clients. Specifically processing limitations for multi-party sessions, we should use a media server to mix everything into single streams that are easier to process. Battery consumption when doing signaling can be fixed by utilizing push notification services. Lastly, echo noise issues are easily avoided by using a headset until the \gls{aec} for mobile devices improve.